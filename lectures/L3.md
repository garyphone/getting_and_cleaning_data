# Week 3

## Subsetting and Sorting

**Subsetting - quick review**

```
set.seed(12345)
X <- data.frame("var1"=sample(1:5), "var2"=sample(6:10), "var3"=sample(11:15))
X <- X[sample(1:5),]; X$var2[c(1,3)] = NA
X
```

**Logicals ands and ors**

```
X[(X$var1 <= 3 & X$var3 > 11),]
```

```
X[(X$var1 <= 3 | X$var3 > 15),]
```

**Dealing with missing values**

```
X[which(X$var2 > 8),]
```

**Sorting**

```
sort(X$var1)
```

```
sort(X$var1, decreasing = TRUE)
```

```
sort(X$var2, na.last = TRUE)
```

**Ordering**

```
X[order(X$var1),]
```

```
X[order(X$var1, X$var3),]
```

**Ordering with plyr**

```
library(plyr)
arrange(X, var1)
```

**Adding rows and columns**

```
X$var4 <- rnorm(5)
X
```

```
Y <- cbind(X, rnorm(5))
Y
```

**Notes and further resources**

* Andrew Jaffe's lecture notes: http://www.biostat.jhsph.edu/~ajaffe/lec_winterR/Lecture%202.pdf

## Summarizing Data

**Getting the data from the web**

see previous lectures

**Look at a bit of the data**

```
head(restData, n=3)
```

```
tail(restData, n=3)
```

**Make summary**

```
summary(restData)
```

**Mpre in depth information**

```
str(restData)
```

**Quantiles of quantitative variables**

```
quantile(restData$councilDistrict, na.rm=TRUE)
```

```
quantile(restData$councilDistrict, prob=c(0.5,0.75,0.9))
```

**Make table**

```
table(restData$zipCode, useNA="ifany")
```

**Check for missing values**

```
sum(is.na(restData$councilDistrict))
```

```
any(is.na(restData$councilDistrict))
```

```
all(restData$zipCode > 0)
```

**Row and columns sums**

```
colSums(is.na(restData))
```

```
all(colSums(is.na(restData))==0)
```

**Values with specific characteristics**

```
table(restData$zipCode %in% c("21212"))
```

**Size of a data set**

```
fakeData = rnorm(1e5)
object.size(fakeData)
```

```
print(object.size(fakeData), units="Mb")
```

## Creating New Variables

**Why create new variables?**

* Often the raw data won't have a value you are looking for

* You will need to transform the data to get the values you would like

* Usually you will add those values to the data frames you are working with

* Common variables to create

	* Missingness indicators
	
	* "Cutting up" quantitative variables
	
	* Applying transforms
	
**Getting the data from the web**

see previous lectures before

**Creating sequences**

*Sometimes you need an index for your data set*

```
s1 <- seq(1,10,by=2); s1
```

```
s2 <- seq(1,10,length=3); s2
```

```
x <- c(1,3,8,25,100); seq(along = x)
```

**Subsetting variables**

```
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
```

**Creating binary variables**

```
restData$zipWrong = ifelse(restData$zipCode < 0, TRUE, FALSE)
table(restData$zipWrong, restData$zipCode < 0)
```

**Creating categorical variables**

```
restData$zipGroups = cut(restData$zipCode, breaks=quantile(restData$zipCode))
table(restData$zipGroups)
```

```
table(restData$zipGroups, restData$zipCode)
```

**Easier cutting**

```
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode, g=4)
table(restData$zipGroups)
```

**Creating factor variables**

```
restData$zfc <- factor(restData$zipCode)
restData$zfc[1:10]
```

**Levels of factor variables**

```
yesno <- sample(c("yes","no"), size=10, replace=TRUE)
yesnofac = factor(yesno, levels=c("yes","no"))
relevel(yesnofac, ref="yes") 
```

**Cutting produces factor variables**

```
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode, g=4)
table(restData$zipGroups)
```

**Using the mutate function**

```
library(Hmisc); library(plyr)
restData2 = mutate(restData, zipGroups=cut2(zipCode,g=4))
table(restData2$zipGroups)
```

**Common transforms**

* `abs(x)` absolute value

* `sqrt(x)` square root

* `ceiling(x)` ceiling(3,475) is 4

* `floor(x)` floor(3.475) is 3

* `round(x,digits=n)` round(3.475,digits=2) is 3.48

* `signif(x,digits=m)` signif(3.475,digits=2) is 3.5

* `cos(x)`, `sin(x)` etc.

* `log(x)` natural logarithm

* `log2(x)`, `log10(x)` other common logs

* `exp(x)` exponentiating x

**Notes and further reading**

* A tutorial from the developer of plyr: http://plyr.had.co.nz/09-user/

* Andrew Jaffe's R notes: http://www.biostat.jhsph.edu/~ajaffe/lec_winterR/Lecture%202.pdf

## Reshaping Data

**The goal is tidy data**

1. Each variable forms a column

2. Each observation forms a row

3. Each table/file stores data about one kind of observation (e.g. people/hospitals)

**Start with reshaping**

```
library(reshape2)
head(mtcars)
```

**Melting data frames**

```
mtcars$carname <- rownames(mtcars)
carMelt <- melt(mtcars, id=c("carname","gear","cyl"), measure.vars=c("mpg","hp"))
head(carMelt,n=3)
```

**Casting data frames**

```
cylData <- dcast(carMelt, cyl ~ variable)
cylData
```

```
cylData <- dcast(carMelt, cyl ~ variable,mean)
cylData
```

**More information**

* A tutorial from the developer of plyr: http://plyr.had.co.nz/09-user/

* A nice reshape tutorial: http://www.slideshare.net/jeffreybreen/reshaping-data-in-r

* A good plyr primer: http://www.r-bloggers.com/a-quick-primer-on-split-apply-combine-problems/

* See also the functions

	* acast - for casting as multi-dimensional arrays
	
	* arrange - for faster reordering without using order() commands
	
	* mutate - adding new variables
	
## Managing Data Frames with dply - Introduction

**dply**

The data frame is a key data structure in statistics and in R

* There is one observation per row

* Each column represents a variable or measure ir characteristic

* Primary implementation that you will use is the default R implementation

* Other implementations, particularly relational databases systems

## dplyr Verbs

* `select`: return a subset of the columns of a data frame

* `filter`: extract a subset of rows from a data frame based on logical conditions

* `arrange`: reorder rows of a data frame

* `rename`: rename variables in a data frame

* `mutate`: add new variables/columns or transform existing variables

* `summarize`: generate summary statistics of different variables in the data frame, possibly within strata

**dplyr Properties**

* The first argument is a data frame

* The subsequent arguments describe what to do with it, and you can refer to columns in the data frame
directly without using the $ operator (just use the names)

* The result is a new data frame

* Data frames must be properly formatted and annotated for this to all be useful






















	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
























