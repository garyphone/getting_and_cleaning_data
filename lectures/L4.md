# Week 4

## Editing Text Variables

**Fixing character vectors - tolower(), toupper()**

```
tolower(names(cameraData))
```

**Fixing character vectors - strsplit()**

* Good for automatically splitting variable names

* Important parameters: x, split

```
splitNames = strsplit(names(cameraData), "\\,")
splitNames[[5]]
```

**Quick aside - lists**

```
mylist <- list(letters = c("A", "b", "c"), numbers = 1:3, matrix(1:25, ncol = 5))
head(mylist)
```

**Fixing character vectors - sapply()**

* Applies a function to each element in a vector or list

* Important parameters: X, FUN

```
firstElement <- function(x){x[1]}
sapply(splitNames, firstElement)
```

**Important points about text in data sets**

* Names of variables should be

	* All lower case when possible
	
	* Descriptive (Diagnosis versus Dx)
	
	* Not duplicated
	
	* Not have underscores or dots or white spaces
	
* Variables with character values

	* Should usually be made into factor variables (depends on application)
	
	* Should be descriptive (use TRUE/FALSE instand of 1/0 and Male/Female versus 1/0 or M/F)

## Regular Expressions I

**Regular expressions**

* Regular expressions can be thought of as a combination of literals and *metacharacters*

* To draw an analogy with natural language, think of literal text forming the words of this language, and 
the metacharacters defining its grammar

* Regular expressions have a rich set of metacharacters

* Simplest pattern consists only of literals; a match occurs if the sequence of literals occurs anywhere in the 
text being tested

We need a way to expressions

* whitespace word boundaries

* set of literals

* the beginning and end of a line

* alternatives ("war" or "peace") Metacharacters to the rescue!

## Regular Expressions II

**More Metacharacters: |**

This does not mean "pipe" in the context of regular expressions, instead it translates to "or".
We can use it to combine two expressions, the subexpressions being called alternatives

**More Metacharacters: ?**

The question mark indicates that the indicated expression is optional

**One thing to note...**

In the following

```
[Gg]eorge( [Ww]\.)? [Bb]ush
```

we wanted to match a "." as a literal period; to do that, we had to "escape" the metacharacter, preceding it
with a backslash. In general, we have to do this for any metacharacter we want to include in our match.

**More metacharacters: * and +**

The * and + signs are metacharacters used to indicate repetition; * means "any number, including none, of the item"
and + means "at least one of the item"

**More metacharacters: { and }**

{ and } are referred to as interval quantifiers; then let us specify the minimum and maximum number of matches of an 
expression

**More metacharacters: ( and ) revisited**

* In most implementations of regular expressions, the parentheses not only limit the scope of alternatives divided by a 
"|", but also can be used to "remember" text matched by the subexpression enclosed

* We refer to the matched text with \1, \2, etc.

**Summary**

* Regular expressions are used in many different languages; not unique to R

* Regular expressions are composed of literals and metacharacters that represent sets or 
classes of characters/words

* Text processing via regular expressions is a very powerful way to extract data from "unfriendly"
sources (not all data comes as a CSV file)

* Used with the functions `grep, grepl, sub, gsub` and others that involve searching for text strings

## Working with Dates

**Starting simple**

```
d1 = date()
d1
```

**Date class**

```
d2 = Sys.Date()
d2
```

**Formatting dates**

`%d` = day as number (0-31), `%a` = abbreviated weekday, `%A` = unabbreviated weekday, `%m` = month (00-12),
`%b` = abbreviated month, `%B` = unabbreviated month, `%y` =  digit year, `%Y` = four digit year

```
format(d2, "%a %b %d")
```

**Creating dates**

```
x = c("1jan1960", "2jan1960", "31mar1960", "30jul1960"); z = as.Date(x, "%d%b%Y")
```

```
z[1] - z[2]
```

```
as.numeric(z[1]-z[2])
```

**Converting to Julian**

```
weekdays(d2)
```

```
julian(d2)
```

**Lubridate**

```
library(lubridate); ymd("20140108")
```

```
mdy("08/04/2013")
```

```
dmy("03-04-2013")
```

**Dealing with times**

```
ymd_hms("2011-08-03 10:15:03")
```

```
ymd_hms("2011-08-03 10:15:03", tz="Pacific/Auckland")
```

```
?Sys.timezone
```

**Notes and further resources**

* More information in this nice lubridate tutorial: http://www.r-statistics.com/2012/03/do-more-with-dates-and-times-in-r-with-lubridate-1-1-0/

* The lubridate vignette is the same content: http://cran.r-project.org/web/packags/lubridate/vignettes/lubridate.html

* Ultimately you want your dates and times as class "Date" or the classes "POSIXct", "POSIXlt".

## Data Resources

* United Nations: http://data.un.org/

* U.S. : http://www.data.gov/

* United Kingdom: http://data.gov.uk/

* France: http://www.data.gouv.fr/

* Ghana: http://data.gov.gh/

* Australia: http://data.gov.au/

* Germany: https://www.govdata.de/

* Hong Kong: http://www.gov.hk/en/theme/psi/datasets/

* Japan: http://www.data.go.jp/

* Many more: http://www.data.gov/opendatasites

**Gapminder**

http://www.gapminder.org/

**Survey data from the United States**

http://www.asdfree.com/

**Infochimps Marketplace**

http://www.infochimps.com/marketplace

**Kaggle**

http://www.kaggle.com/

**Collections by data scientists**

* Hillary Mason: http://bitly.com/bundles/hmason/1

* Peter Skomoroch: http://delicious.com/pskomoroch/dataset

* Jeff Hammerbacker: http://www.quora.com/Jeff-Hammerbacker/Introduction-to-Data-Science-Data-Sets

* Gregory Piatetsky-Shapiro: http://www.kdnuggets.com/gps.html

* http://blog.mortardata.com/post/67652898761/6-dataset-lists-curated-by-data-scientists

**More specialized collections**

* Stanford Large Network Data

* UCI Machine Learning

* KDD Nugets Datasets

* CMU Statlib

* Gene expression omnibus

* ArXiv Data

* Public Data Sets on Amazon Web Services


















































